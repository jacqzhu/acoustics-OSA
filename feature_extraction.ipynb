{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d8e2afb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TagB\\.conda\\envs\\PyTorch\\lib\\site-packages\\paramiko\\transport.py:219: CryptographyDeprecationWarning: Blowfish has been deprecated\n",
      "  \"class\": algorithms.Blowfish,\n"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7773c673",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_path = r\"R:\\Speech and Craniofacial analysis\\Collected Data\\UMich Data\\April_16_2025\\Jacqueline\\April16_allSegments_processed.xlsx\"\n",
    "metadata = pd.read_excel(metadata_path)\n",
    "metadata = metadata[~metadata['vowel'].str.contains('sentence', case=False, na=False)]  # Filter out sentences\n",
    "metadata = metadata.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c2861b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "import warnings\n",
    "import librosa\n",
    "from scipy import signal\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def logEnt(sigHist):\n",
    "  s = np.log(sigHist+1E-6)**2\n",
    "  return s.sum()\n",
    "\n",
    "def ShanonEnt(y):\n",
    "  binwidth = (3.49*y.std())/(np.power(len(y),1/3))\n",
    "  bins=np.arange(y.min(), y.max() + binwidth, binwidth)\n",
    "  c= np.histogram(y,bins=bins)\n",
    "  pdf = c[0]/c[0].sum()\n",
    "  Ent = scipy.stats.entropy(pdf)\n",
    "  return [pdf,Ent]\n",
    "\n",
    "def bandpower(x, fs, fmin, fmax):\n",
    "    f, Pxx = scipy.signal.periodogram(x, fs=fs)\n",
    "    Pxx = Pxx/Pxx.mean()\n",
    "    ind_min = np.argmax(f > fmin) - 1\n",
    "    ind_max = np.argmax(f > fmax) - 1\n",
    "    return np.trapz(Pxx[ind_min: ind_max], f[ind_min: ind_max])\n",
    "\n",
    "def featureExtractor(inputSignal,sr):\n",
    "    d = {}\n",
    "\n",
    "    d[\"shEnt\"] = []\n",
    "    d[\"logEnt\"] = []\n",
    "  \n",
    "    d[\"bandPow0_10\"] = []\n",
    "    d[\"bandPow10_20\"] = []\n",
    "    d[\"bandPow20_30\"] = []\n",
    "    d[\"bandPow30_40\"] = []\n",
    "    d[\"bandPow40_50\"] = []\n",
    "    d[\"bandPow50_60\"] = []\n",
    "  \n",
    "    for z in range(13): d[\"mfcc_\"+str(z)] = []\n",
    "    for z in range(13): d[\"dmfcc_\"+str(z)] = []\n",
    "    for z in range(13): d[\"ddmfcc_\"+str(z)] = []\n",
    "  \n",
    "    for z in range(12): d[\"chroma\"+str(z)] = []\n",
    "  \n",
    "    d[\"spec_centroid\"] = []\n",
    "    d[\"spec_bandwith\"] = []\n",
    "    d[\"spec_flatness\"] = []\n",
    "    d[\"spec_rolloff\"] = []\n",
    "    for z in range(7): d[\"spec_contrast\"+str(z)] = []\n",
    "  \n",
    "    for z in range(4): d[\"poly\"+str(z)] = []\n",
    "  \n",
    "    d[\"zero_crossing\"] =[]\n",
    "  \n",
    "    d[\"tempgram_mean\"] = []\n",
    "    d[\"tempgram_var\"] = []\n",
    "    d[\"tempgram_kurt\"] = []\n",
    "    d[\"tempgram_skew\"] = []\n",
    "  \n",
    "    d[\"mean\"] = []\n",
    "    d[\"var\"] = []\n",
    "    d[\"skew\"] = []\n",
    "    d[\"kurt\"] = []\n",
    "    d[\"range\"] = []\n",
    "    d[\"diff_SMA\"] = []\n",
    "  \n",
    "    d['PXX_skew'] = []\n",
    "    d['PXX_RMS'] = []\n",
    "    d[\"PXX_mean\"] = []\n",
    "  \n",
    "    d['PXX_shEnt'] = []\n",
    "    d['PXX_logEnt'] = []\n",
    "    d[\"PXX_range\"] = []\n",
    "    d[\"PXX_diff_SMA\"] = []\n",
    "  \n",
    "    s = inputSignal\n",
    "    pdf,Ent = ShanonEnt(s) #Shannon Entropy   \n",
    "\n",
    "    # Statistical features from signal\n",
    "    d[\"mean\"].append(np.mean(s))\n",
    "    d[\"var\"].append(np.var(s))\n",
    "    d[\"skew\"].append(scipy.stats.skew(s))\n",
    "    d[\"kurt\"].append(scipy.stats.kurtosis(s))\n",
    "    d[\"range\"].append(s.max()-s.min())\n",
    "    d[\"diff_SMA\"].append(abs(np.diff(s,1)).sum())\n",
    "\n",
    "    d[\"shEnt\"].append(Ent) #Shanon Entropy\n",
    "    d[\"logEnt\"].append(logEnt(pdf)) #Log Entropy\n",
    "\n",
    "    s = (s-s.mean())/(s.std())\n",
    "\n",
    "    # MFCC/DeltaMFCC/ DeltaDeltaMFCC\n",
    "    mfccs = librosa.feature.mfcc(y=s, sr=sr, n_mfcc=13)\n",
    "    m = np.median(mfccs,axis=1)\n",
    "\n",
    "    mfcc_delta = np.diff(mfccs,1)\n",
    "    mdelta = np.median(mfcc_delta,axis=1)\n",
    "\n",
    "    mfcc_deltadelta = np.diff(mfcc_delta,1)\n",
    "    mdeltadelta = np.median(mfcc_deltadelta,axis=1)\n",
    "\n",
    "    for z in range(13): d[\"mfcc_\"+str(z)].append(m[z])\n",
    "    for z in range(13): d[\"dmfcc_\"+str(z)].append(mdelta[z])\n",
    "    for z in range(13): d[\"ddmfcc_\"+str(z)].append(mdeltadelta[z])\n",
    "\n",
    "    # Chroma-related features\n",
    "    S = np.abs(librosa.stft(s))**2\n",
    "    chroma = librosa.feature.chroma_stft(S=S, sr=sr)\n",
    "    chMax = np.median(chroma,axis=1)\n",
    "\n",
    "    for z in range(12): d[\"chroma\"+str(z)].append(chMax[z])\n",
    "\n",
    "    # Spectral-related features\n",
    "    contr = librosa.feature.spectral_contrast(y=s,sr=sr,n_bands=6)\n",
    "    contrMed = np.median(contr,axis=1)\n",
    "    for z in range(7): d[\"spec_contrast\"+str(z)].append(contrMed[z])\n",
    "\n",
    "    d[\"spec_centroid\"].append(np.median(librosa.feature.spectral_centroid(s,sr=sr)))\n",
    "    d[\"spec_bandwith\"].append(np.median(librosa.feature.spectral_bandwidth(s,sr=sr)))\n",
    "    d[\"spec_flatness\"].append(np.median(librosa.feature.spectral_flatness(s)))\n",
    "    d[\"spec_rolloff\"].append(np.median(librosa.feature.spectral_rolloff(y=s, sr=sr)))\n",
    "\n",
    "    # Get coefficients of fitting an 3rd-order polynomial to the columns of a spectrogram.\n",
    "    polyFeat = librosa.feature.poly_features(y=s,sr=sr,order=3)\n",
    "    polyMed = np.median(polyFeat,axis=1)\n",
    "    for z in range(4): d[\"poly\"+str(z)].append(polyMed[z])\n",
    "\n",
    "    # Zero crossing rate\n",
    "    d[\"zero_crossing\"].append(np.median(librosa.feature.zero_crossing_rate(y=s,frame_length= len(s)),axis=1)[0])\n",
    "\n",
    "    # Statistical features from tempogram\n",
    "    tempGram = librosa.feature.tempogram(y=s, sr=sr)\n",
    "    d[\"tempgram_mean\"].append(np.mean(tempGram))\n",
    "    d[\"tempgram_var\"].append(np.var(tempGram))\n",
    "    d[\"tempgram_kurt\"].append(scipy.stats.kurtosis(tempGram).mean())\n",
    "    d[\"tempgram_skew\"].append(scipy.stats.skew(tempGram).mean())\n",
    "\n",
    "    # Band powers\n",
    "    d[\"bandPow0_10\"].append(bandpower(s, sr, 0.1, int(sr/12)))\n",
    "    d[\"bandPow10_20\"].append(bandpower(s, sr, int(sr/12), int(2*sr/12)))\n",
    "    d[\"bandPow20_30\"].append(bandpower(s, sr, int(2*sr/12), int(3*sr/12)))\n",
    "    d[\"bandPow30_40\"].append(bandpower(s, sr, int(3*sr/12), int(4*sr/12)))\n",
    "    d[\"bandPow40_50\"].append(bandpower(s, sr, int(4*sr/12), int(5*sr/12)))\n",
    "    d[\"bandPow50_60\"].append(bandpower(s, sr, int(5*sr/12), int(sr/2)))\n",
    "\n",
    "\n",
    "    f,pxx = signal.welch((s-s.mean())/s.std(), fs=sr, window='hann', nperseg=16,noverlap=15, nfft=2048)\n",
    "    fIntent = np.where(f>7200)\n",
    "    pxx = pxx[0:fIntent[0][0]-1]\n",
    "\n",
    "    d['PXX_skew'].append(scipy.stats.skew(pxx))\n",
    "    d['PXX_RMS'].append(np.sqrt(np.mean(pxx**2)))\n",
    "    d['PXX_mean'].append(pxx.mean())\n",
    "    d[\"PXX_range\"].append(pxx.max()-pxx.min())\n",
    "\n",
    "    pdf,Ent = ShanonEnt(pxx) #Shannon Entropy\n",
    "    d[\"PXX_shEnt\"].append(Ent) #Shanon Entropy\n",
    "    d[\"PXX_logEnt\"].append(logEnt(pdf)) #Log Entropy\n",
    "    d[\"PXX_diff_SMA\"].append(abs(np.diff(pxx,1)).sum())\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9424119b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "175it [03:28,  1.19s/it]\n"
     ]
    }
   ],
   "source": [
    "import torchaudio\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "df_features_all = pd.DataFrame()\n",
    "k = 0\n",
    "\n",
    "for idx, row in tqdm(metadata.iterrows()):\n",
    "    file_path = row['location']\n",
    "    waveform, sample_rate = torchaudio.load(file_path)\n",
    "    if waveform.shape[0] > 1:\n",
    "        waveform = waveform.mean(dim=0)\n",
    "    waveform = waveform.squeeze().numpy()\n",
    "    df_feature = featureExtractor(np.array(waveform),sample_rate)\n",
    "    df_dummy = pd.concat([pd.DataFrame(metadata.loc[k]).transpose().reset_index(),pd.DataFrame(df_feature).reset_index(drop=True)],axis=1)\n",
    "    df_features_all = pd.concat([df_features_all,df_dummy],ignore_index = True)\n",
    "    \n",
    "    k+= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "77339dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features_all.to_excel('DemographPlusAcousticFeatures_UMich_SRK.xlsx')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
